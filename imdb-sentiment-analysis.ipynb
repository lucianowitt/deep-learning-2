{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de sentimento em reviews de filmes\n",
    "\n",
    "Gibson Weinert, Luciano Gonçalves, João Paulo Medeiros\n",
    "\n",
    "### Dataset\n",
    "\n",
    "https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data\n",
    "\n",
    "### Classes\n",
    "1. negative\n",
    "2. somewhat negative\n",
    "3. neutral\n",
    "4. somewhat positive\n",
    "5. positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise inicial dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train = pd.read_csv('./data/train.tsv', '\\t')\n",
    "print(original_train.shape)\n",
    "original_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_test = pd.read_csv('./data/test.tsv', '\\t')\n",
    "print(original_test.shape)\n",
    "original_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O conjunto original de teste não possui as labels, pois foi concebido para o desafio.**\n",
    "\n",
    "**Vamos desconsiderá-lo e dividir o conjunto original de treino em treino, validação e teste.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos datasets de treino, validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 99878 \n",
      "Valid: 24970 \n",
      "Test:  31212 \n",
      "\n",
      "Total: 156060\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = original_train['Phrase']\n",
    "y = original_train['Sentiment']\n",
    "\n",
    "X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_other, y_other, test_size=0.2, stratify=y_other)\n",
    "\n",
    "print('Train:', len(X_train), '\\nValid:', len(X_valid), '\\nTest: ', len(X_test), '\\n\\nTotal:', len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame({'y': y_train, 'X': X_train})\n",
    "valid = pd.DataFrame({'y': y_train, 'X': X_train})\n",
    "test = pd.DataFrame({'y': y_train, 'X': X_train})\n",
    "\n",
    "train.to_csv('./data/train.csv', '\\t', header=False, index=False)\n",
    "train.to_csv('./data/valid.csv', '\\t', header=False, index=False)\n",
    "train.to_csv('./data/test.csv', '\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit_transform(X)\n",
    "\n",
    "vocab = {}\n",
    "vocab['word2idx'] = {'<pad>': 0, '<start>': 1, '<end>': 2, '<unk>': 3}\n",
    "vocab['idx2word'] = {'0': '<pad>', '1': '<start>', '2': '<end>', '3': '<unk>'}\n",
    "vocab['idx'] = [0, 1, 2, 3]\n",
    "\n",
    "for k, v in enumerate(vectorizer.vocabulary_.keys()):\n",
    "    vocab['word2idx'][v] = k + 4\n",
    "    vocab['idx2word'][str(k + 4)] = v\n",
    "    vocab['idx'].append(k + 4)\n",
    "\n",
    "with open('./data/vocab.json', 'w') as outfile:\n",
    "    json.dump(vocab, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from data import get_loaders\n",
    "from train import train, test, check_input\n",
    "import models \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_instance(instance_id):\n",
    "    print('\\nExample: ')\n",
    "    print(train_loader.dataset.texts[instance_id])\n",
    "    print('\\nLabel Number: ')\n",
    "    print(train_loader.dataset.labels[instance_id])\n",
    "    print('\\nLabel String: ')\n",
    "    print(classes[train_loader.dataset.labels[instance_id]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "  'negative',\n",
    "  'somewhat negative',\n",
    "  'neutral',\n",
    "  'somewhat positive',\n",
    "  'positive'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  99878 99878\n",
      "Valid size :  99878 99878\n",
      "\n",
      "Example: \n",
      "the whole\n",
      "\n",
      "Label Number: \n",
      "2\n",
      "\n",
      "Label String: \n",
      "neutral\n",
      "\n",
      "Example: \n",
      "Shiri is an action film that delivers on the promise of excitement , but\n",
      "\n",
      "Label Number: \n",
      "2\n",
      "\n",
      "Label String: \n",
      "neutral\n",
      "\n",
      "Example: \n",
      "courageous\n",
      "\n",
      "Label Number: \n",
      "3\n",
      "\n",
      "Label String: \n",
      "somewhat positive\n",
      "\n",
      "Example: \n",
      ", this sappy ethnic sleeper proves that not only blockbusters pollute the summer movie pool .\n",
      "\n",
      "Label Number: \n",
      "2\n",
      "\n",
      "Label String: \n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "data_path = './data/'\n",
    "batch_size = 128\n",
    "device_name = 'cuda'\n",
    "nb_epochs = 10\n",
    "log_interval = 100\n",
    "lr = 1e-3\n",
    "\n",
    "device = torch.device(device_name)\n",
    "\n",
    "train_loader, valid_loader = get_loaders(\n",
    "    data_path=data_path, \n",
    "    batch_size=batch_size, \n",
    "    splits=['train', 'valid'],\n",
    ")\n",
    "\n",
    "nb_words = len(train_loader.dataset.vocab)\n",
    "\n",
    "print(\n",
    "    'Train size: ', \n",
    "    len(train_loader.dataset.texts),\n",
    "    len(train_loader.dataset.labels)\n",
    ")\n",
    "print(\n",
    "    'Valid size : ', \n",
    "    len(valid_loader.dataset.texts),\n",
    "    len(valid_loader.dataset.labels)\n",
    ")\n",
    "\n",
    "plot_instance(0)\n",
    "plot_instance(1015)\n",
    "plot_instance(5136)\n",
    "plot_instance(8974)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pooling(instances, lens):\n",
    "    return torch.stack([\n",
    "        text[:l].mean(0) for text, l in zip(instances, lens)\n",
    "    ])\n",
    "\n",
    "\n",
    "class TextLSTM(nn.Module):\n",
    "    def __init__(self, num_embeddings=99878, embedding_dim=100):\n",
    "        '''\n",
    "            num_embeddings: number of words in the dictionary\n",
    "            embedding_dim: size of the word-embedding vector\n",
    "        '''\n",
    "        super(TextLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=num_embeddings, \n",
    "            embedding_dim=embedding_dim,\n",
    "        )\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=100, hidden_size=32, \n",
    "            batch_first=True, bidirectional=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(32*2, len(classes))\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        # Transforma índices das palavras em vetores \n",
    "        x = self.embedding(x)\n",
    "        # Processa vetores das palavras com uma rede recorrente\n",
    "        hidden, output = self.rnn(x)\n",
    "        # Faz a média das ativações de todas as iterações recorrentes\n",
    "        vector = average_pooling(hidden, lengths)\n",
    "        # Camada linear para classificacao\n",
    "        x = self.fc(vector)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "model = TextLSTM()\n",
    "model = model.to(device)\n",
    "\n",
    "dummy_pred = check_input(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Luciano\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   1 [     0/ 99878 (0%)]\tLoss: 1.588900\n",
      "Train Epoch:   1 [ 12800/ 99878 (13%)]\tLoss: 1.144452\n",
      "Train Epoch:   1 [ 25600/ 99878 (26%)]\tLoss: 1.193114\n",
      "Train Epoch:   1 [ 38400/ 99878 (38%)]\tLoss: 1.187045\n",
      "Train Epoch:   1 [ 51200/ 99878 (51%)]\tLoss: 1.272250\n",
      "Train Epoch:   1 [ 64000/ 99878 (64%)]\tLoss: 0.932374\n",
      "Train Epoch:   1 [ 76800/ 99878 (77%)]\tLoss: 1.036551\n",
      "Train Epoch:   1 [ 89600/ 99878 (90%)]\tLoss: 0.983673\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0079, Accuracy: 59284/99878 (59.36%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   2 [     0/ 99878 (0%)]\tLoss: 1.060094\n",
      "Train Epoch:   2 [ 12800/ 99878 (13%)]\tLoss: 1.030559\n",
      "Train Epoch:   2 [ 25600/ 99878 (26%)]\tLoss: 1.034394\n",
      "Train Epoch:   2 [ 38400/ 99878 (38%)]\tLoss: 0.964436\n",
      "Train Epoch:   2 [ 51200/ 99878 (51%)]\tLoss: 0.813428\n",
      "Train Epoch:   2 [ 64000/ 99878 (64%)]\tLoss: 0.931349\n",
      "Train Epoch:   2 [ 76800/ 99878 (77%)]\tLoss: 1.068571\n",
      "Train Epoch:   2 [ 89600/ 99878 (90%)]\tLoss: 0.909124\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0067, Accuracy: 65589/99878 (65.67%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   3 [     0/ 99878 (0%)]\tLoss: 0.760808\n",
      "Train Epoch:   3 [ 12800/ 99878 (13%)]\tLoss: 0.850281\n",
      "Train Epoch:   3 [ 25600/ 99878 (26%)]\tLoss: 0.765157\n",
      "Train Epoch:   3 [ 38400/ 99878 (38%)]\tLoss: 0.766661\n",
      "Train Epoch:   3 [ 51200/ 99878 (51%)]\tLoss: 0.929638\n",
      "Train Epoch:   3 [ 64000/ 99878 (64%)]\tLoss: 0.793122\n",
      "Train Epoch:   3 [ 76800/ 99878 (77%)]\tLoss: 0.789582\n",
      "Train Epoch:   3 [ 89600/ 99878 (90%)]\tLoss: 0.767506\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0060, Accuracy: 69126/99878 (69.21%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   4 [     0/ 99878 (0%)]\tLoss: 0.707842\n",
      "Train Epoch:   4 [ 12800/ 99878 (13%)]\tLoss: 0.821850\n",
      "Train Epoch:   4 [ 25600/ 99878 (26%)]\tLoss: 0.774626\n",
      "Train Epoch:   4 [ 38400/ 99878 (38%)]\tLoss: 0.771599\n",
      "Train Epoch:   4 [ 51200/ 99878 (51%)]\tLoss: 0.692012\n",
      "Train Epoch:   4 [ 64000/ 99878 (64%)]\tLoss: 0.802622\n",
      "Train Epoch:   4 [ 76800/ 99878 (77%)]\tLoss: 0.792517\n",
      "Train Epoch:   4 [ 89600/ 99878 (90%)]\tLoss: 0.810664\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0059, Accuracy: 69881/99878 (69.97%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   5 [     0/ 99878 (0%)]\tLoss: 0.695105\n",
      "Train Epoch:   5 [ 12800/ 99878 (13%)]\tLoss: 0.699525\n",
      "Train Epoch:   5 [ 25600/ 99878 (26%)]\tLoss: 0.794220\n",
      "Train Epoch:   5 [ 38400/ 99878 (38%)]\tLoss: 0.729904\n",
      "Train Epoch:   5 [ 51200/ 99878 (51%)]\tLoss: 0.766940\n",
      "Train Epoch:   5 [ 64000/ 99878 (64%)]\tLoss: 0.725924\n",
      "Train Epoch:   5 [ 76800/ 99878 (77%)]\tLoss: 0.678770\n",
      "Train Epoch:   5 [ 89600/ 99878 (90%)]\tLoss: 0.846732\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0058, Accuracy: 70206/99878 (70.29%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   6 [     0/ 99878 (0%)]\tLoss: 0.697507\n",
      "Train Epoch:   6 [ 12800/ 99878 (13%)]\tLoss: 0.801898\n",
      "Train Epoch:   6 [ 25600/ 99878 (26%)]\tLoss: 0.792458\n",
      "Train Epoch:   6 [ 38400/ 99878 (38%)]\tLoss: 0.702808\n",
      "Train Epoch:   6 [ 51200/ 99878 (51%)]\tLoss: 0.818941\n",
      "Train Epoch:   6 [ 64000/ 99878 (64%)]\tLoss: 0.622128\n",
      "Train Epoch:   6 [ 76800/ 99878 (77%)]\tLoss: 0.817806\n",
      "Train Epoch:   6 [ 89600/ 99878 (90%)]\tLoss: 0.813102\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0057, Accuracy: 70565/99878 (70.65%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   7 [     0/ 99878 (0%)]\tLoss: 0.634808\n",
      "Train Epoch:   7 [ 12800/ 99878 (13%)]\tLoss: 0.816814\n",
      "Train Epoch:   7 [ 25600/ 99878 (26%)]\tLoss: 0.677137\n",
      "Train Epoch:   7 [ 38400/ 99878 (38%)]\tLoss: 0.729295\n",
      "Train Epoch:   7 [ 51200/ 99878 (51%)]\tLoss: 0.678041\n",
      "Train Epoch:   7 [ 64000/ 99878 (64%)]\tLoss: 0.720979\n",
      "Train Epoch:   7 [ 76800/ 99878 (77%)]\tLoss: 0.709157\n",
      "Train Epoch:   7 [ 89600/ 99878 (90%)]\tLoss: 0.751712\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0057, Accuracy: 70602/99878 (70.69%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   8 [     0/ 99878 (0%)]\tLoss: 0.829464\n",
      "Train Epoch:   8 [ 12800/ 99878 (13%)]\tLoss: 0.670358\n",
      "Train Epoch:   8 [ 25600/ 99878 (26%)]\tLoss: 0.868780\n",
      "Train Epoch:   8 [ 38400/ 99878 (38%)]\tLoss: 0.847480\n",
      "Train Epoch:   8 [ 51200/ 99878 (51%)]\tLoss: 0.721092\n",
      "Train Epoch:   8 [ 64000/ 99878 (64%)]\tLoss: 0.728483\n",
      "Train Epoch:   8 [ 76800/ 99878 (77%)]\tLoss: 0.724451\n",
      "Train Epoch:   8 [ 89600/ 99878 (90%)]\tLoss: 0.663775\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0057, Accuracy: 70643/99878 (70.73%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   9 [     0/ 99878 (0%)]\tLoss: 0.652803\n",
      "Train Epoch:   9 [ 12800/ 99878 (13%)]\tLoss: 0.744682\n",
      "Train Epoch:   9 [ 25600/ 99878 (26%)]\tLoss: 0.708279\n",
      "Train Epoch:   9 [ 38400/ 99878 (38%)]\tLoss: 0.682620\n",
      "Train Epoch:   9 [ 51200/ 99878 (51%)]\tLoss: 0.663687\n",
      "Train Epoch:   9 [ 64000/ 99878 (64%)]\tLoss: 0.676247\n",
      "Train Epoch:   9 [ 76800/ 99878 (77%)]\tLoss: 0.769287\n",
      "Train Epoch:   9 [ 89600/ 99878 (90%)]\tLoss: 0.738054\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0057, Accuracy: 70649/99878 (70.74%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  10 [     0/ 99878 (0%)]\tLoss: 0.842071\n",
      "Train Epoch:  10 [ 12800/ 99878 (13%)]\tLoss: 0.805139\n",
      "Train Epoch:  10 [ 25600/ 99878 (26%)]\tLoss: 0.736311\n",
      "Train Epoch:  10 [ 38400/ 99878 (38%)]\tLoss: 0.649547\n",
      "Train Epoch:  10 [ 51200/ 99878 (51%)]\tLoss: 0.727756\n",
      "Train Epoch:  10 [ 64000/ 99878 (64%)]\tLoss: 0.653394\n",
      "Train Epoch:  10 [ 76800/ 99878 (77%)]\tLoss: 0.729520\n",
      "Train Epoch:  10 [ 89600/ 99878 (90%)]\tLoss: 0.802378\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0057, Accuracy: 70666/99878 (70.75%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = train(\n",
    "    model=model, train_loader=train_loader, test_loader=valid_loader,\n",
    "    device=device, optimizer=optimizer, lr_scheduler=lr_scheduler,\n",
    "    nb_epochs=nb_epochs, log_interval=log_interval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
