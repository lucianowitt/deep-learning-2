{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de sentimento em reviews de filmes\n",
    "\n",
    "Gibson Weinert, Luciano Gonçalves, João Paulo Medeiros\n",
    "\n",
    "### Dataset\n",
    "\n",
    "https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data\n",
    "\n",
    "### Classes\n",
    "0. negative\n",
    "1. somewhat negative\n",
    "2. neutral\n",
    "3. somewhat positive\n",
    "4. positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise inicial dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train = pd.read_csv('./data/train.tsv', '\\t')\n",
    "print(original_train.shape)\n",
    "original_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_test = pd.read_csv('./data/test.tsv', '\\t')\n",
    "print(original_test.shape)\n",
    "original_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O conjunto original de teste não possui as labels, pois foi concebido para o desafio.**\n",
    "\n",
    "**Vamos desconsiderá-lo e dividir o conjunto original de treino em treino, validação e teste.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos datasets de treino, validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 99878 \n",
      "Valid: 24970 \n",
      "Test:  31212 \n",
      "\n",
      "Total: 156060\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = original_train['Phrase']\n",
    "y = original_train['Sentiment']\n",
    "\n",
    "X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_other, y_other, test_size=0.2, stratify=y_other)\n",
    "\n",
    "print('Train:', len(X_train), '\\nValid:', len(X_valid), '\\nTest: ', len(X_test), '\\n\\nTotal:', len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame({'y': y_train, 'X': X_train})\n",
    "valid = pd.DataFrame({'y': y_train, 'X': X_train})\n",
    "test = pd.DataFrame({'y': y_train, 'X': X_train})\n",
    "\n",
    "train.to_csv('./data/train.csv', '\\t', header=False, index=False)\n",
    "train.to_csv('./data/valid.csv', '\\t', header=False, index=False)\n",
    "train.to_csv('./data/test.csv', '\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 15244\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit_transform(X)\n",
    "\n",
    "vocab = {}\n",
    "vocab['word2idx'] = {'<pad>': 0, '<start>': 1, '<end>': 2, '<unk>': 3}\n",
    "vocab['idx2word'] = {'0': '<pad>', '1': '<start>', '2': '<end>', '3': '<unk>'}\n",
    "vocab['idx'] = [0, 1, 2, 3]\n",
    "\n",
    "for k, v in enumerate(vectorizer.vocabulary_.keys()):\n",
    "    vocab['word2idx'][v] = k + 4\n",
    "    vocab['idx2word'][str(k + 4)] = v\n",
    "    vocab['idx'].append(k + 4)\n",
    "\n",
    "with open('./data/vocab.json', 'w') as outfile:\n",
    "    json.dump(vocab, outfile)\n",
    "\n",
    "vocabSize = len(vocab['idx'])\n",
    "\n",
    "print('Vocabulary size:', vocabSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from data import get_loaders\n",
    "from train import train, test, check_input\n",
    "import models \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "  'negative',\n",
    "  'somewhat negative',\n",
    "  'neutral',\n",
    "  'somewhat positive',\n",
    "  'positive'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_instance(instance_id):\n",
    "    text = train_loader.dataset.texts[instance_id]\n",
    "    label = train_loader.dataset.labels[instance_id]\n",
    "    label_str = classes[train_loader.dataset.labels[instance_id]]\n",
    "    print('\\nExample:')\n",
    "    print(text)\n",
    "    print('Label:', label, '-', label_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configurações e hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'\n",
    "device_name = 'cuda'\n",
    "batch_size = 1024\n",
    "nb_epochs = 25\n",
    "log_interval = 5\n",
    "lr = 1e-2\n",
    "lr_step = 7\n",
    "num_layers = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  99878 99878\n",
      "Valid size :  99878 99878\n",
      "\n",
      "Example:\n",
      "a huge disappointment coming , as it does , from filmmakers and performers of this calibre\n",
      "Label: 0 - negative\n",
      "\n",
      "Example:\n",
      "too bad to be good\n",
      "Label: 1 - somewhat negative\n",
      "\n",
      "Example:\n",
      "of asparagus\n",
      "Label: 2 - neutral\n",
      "\n",
      "Example:\n",
      "The most offensive thing about the movie\n",
      "Label: 1 - somewhat negative\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(device_name)\n",
    "\n",
    "train_loader, valid_loader = get_loaders(\n",
    "    data_path=data_path, \n",
    "    batch_size=batch_size, \n",
    "    splits=['train', 'valid'],\n",
    ")\n",
    "\n",
    "nb_words = len(train_loader.dataset.vocab)\n",
    "\n",
    "print(\n",
    "    'Train size: ', \n",
    "    len(train_loader.dataset.texts),\n",
    "    len(train_loader.dataset.labels)\n",
    ")\n",
    "print(\n",
    "    'Valid size : ', \n",
    "    len(valid_loader.dataset.texts),\n",
    "    len(valid_loader.dataset.labels)\n",
    ")\n",
    "\n",
    "plot_instance(0)\n",
    "plot_instance(1015)\n",
    "plot_instance(5136)\n",
    "plot_instance(8974)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pooling(instances, lens):\n",
    "    return torch.stack([\n",
    "        text[:l].mean(0) for text, l in zip(instances, lens)\n",
    "    ])\n",
    "\n",
    "\n",
    "class TextLSTM(nn.Module):\n",
    "    def __init__(self, num_embeddings=vocabSize, embedding_dim=100):\n",
    "        '''\n",
    "            num_embeddings: number of words in the dictionary\n",
    "            embedding_dim: size of the word-embedding vector\n",
    "        '''\n",
    "        super(TextLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=num_embeddings, \n",
    "            embedding_dim=embedding_dim,\n",
    "        )\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=100, hidden_size=32, \n",
    "            batch_first=True, bidirectional=True,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(32*2, len(classes))\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        # Transforma índices das palavras em vetores \n",
    "        x = self.embedding(x)\n",
    "        # Processa vetores das palavras com uma rede recorrente\n",
    "        hidden, output = self.rnn(x)\n",
    "        # Faz a média das ativações de todas as iterações recorrentes\n",
    "        vector = average_pooling(hidden, lengths)\n",
    "        # Camada linear para classificacao\n",
    "        x = self.fc(vector)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed\n"
     ]
    }
   ],
   "source": [
    "model = TextLSTM()\n",
    "model = model.to(device)\n",
    "\n",
    "dummy_pred = check_input(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_step,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Luciano\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   1 [     0/ 99878 (0%)]\tLoss: 1.574498\n",
      "Train Epoch:   1 [  5120/ 99878 (5%)]\tLoss: 1.313082\n",
      "Train Epoch:   1 [ 10240/ 99878 (10%)]\tLoss: 1.288216\n",
      "Train Epoch:   1 [ 15360/ 99878 (15%)]\tLoss: 1.256620\n",
      "Train Epoch:   1 [ 20480/ 99878 (20%)]\tLoss: 1.261944\n",
      "Train Epoch:   1 [ 25600/ 99878 (26%)]\tLoss: 1.272873\n",
      "Train Epoch:   1 [ 30720/ 99878 (31%)]\tLoss: 1.184277\n",
      "Train Epoch:   1 [ 35840/ 99878 (36%)]\tLoss: 1.162024\n",
      "Train Epoch:   1 [ 40960/ 99878 (41%)]\tLoss: 1.189728\n",
      "Train Epoch:   1 [ 46080/ 99878 (46%)]\tLoss: 1.178258\n",
      "Train Epoch:   1 [ 51200/ 99878 (51%)]\tLoss: 1.146354\n",
      "Train Epoch:   1 [ 56320/ 99878 (56%)]\tLoss: 1.138569\n",
      "Train Epoch:   1 [ 61440/ 99878 (61%)]\tLoss: 1.172900\n",
      "Train Epoch:   1 [ 66560/ 99878 (66%)]\tLoss: 1.131769\n",
      "Train Epoch:   1 [ 71680/ 99878 (71%)]\tLoss: 1.096159\n",
      "Train Epoch:   1 [ 76800/ 99878 (77%)]\tLoss: 1.084481\n",
      "Train Epoch:   1 [ 81920/ 99878 (82%)]\tLoss: 1.175469\n",
      "Train Epoch:   1 [ 87040/ 99878 (87%)]\tLoss: 1.123863\n",
      "Train Epoch:   1 [ 92160/ 99878 (92%)]\tLoss: 1.110920\n",
      "Train Epoch:   1 [ 97280/ 99878 (97%)]\tLoss: 1.063551\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0010, Accuracy: 57005/99878 (57.07%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   2 [     0/ 99878 (0%)]\tLoss: 1.069328\n",
      "Train Epoch:   2 [  5120/ 99878 (5%)]\tLoss: 1.023019\n",
      "Train Epoch:   2 [ 10240/ 99878 (10%)]\tLoss: 1.045278\n",
      "Train Epoch:   2 [ 15360/ 99878 (15%)]\tLoss: 0.979316\n",
      "Train Epoch:   2 [ 20480/ 99878 (20%)]\tLoss: 1.024605\n",
      "Train Epoch:   2 [ 25600/ 99878 (26%)]\tLoss: 1.005740\n",
      "Train Epoch:   2 [ 30720/ 99878 (31%)]\tLoss: 1.006178\n",
      "Train Epoch:   2 [ 35840/ 99878 (36%)]\tLoss: 0.970123\n",
      "Train Epoch:   2 [ 40960/ 99878 (41%)]\tLoss: 0.984387\n",
      "Train Epoch:   2 [ 46080/ 99878 (46%)]\tLoss: 0.975681\n",
      "Train Epoch:   2 [ 51200/ 99878 (51%)]\tLoss: 0.978846\n",
      "Train Epoch:   2 [ 56320/ 99878 (56%)]\tLoss: 0.948854\n",
      "Train Epoch:   2 [ 61440/ 99878 (61%)]\tLoss: 0.937345\n",
      "Train Epoch:   2 [ 66560/ 99878 (66%)]\tLoss: 0.959705\n",
      "Train Epoch:   2 [ 71680/ 99878 (71%)]\tLoss: 0.886197\n",
      "Train Epoch:   2 [ 76800/ 99878 (77%)]\tLoss: 0.917029\n",
      "Train Epoch:   2 [ 81920/ 99878 (82%)]\tLoss: 0.902898\n",
      "Train Epoch:   2 [ 87040/ 99878 (87%)]\tLoss: 0.898735\n",
      "Train Epoch:   2 [ 92160/ 99878 (92%)]\tLoss: 0.911300\n",
      "Train Epoch:   2 [ 97280/ 99878 (97%)]\tLoss: 0.886679\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0008, Accuracy: 66951/99878 (67.03%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   3 [     0/ 99878 (0%)]\tLoss: 0.824924\n",
      "Train Epoch:   3 [  5120/ 99878 (5%)]\tLoss: 0.774450\n",
      "Train Epoch:   3 [ 10240/ 99878 (10%)]\tLoss: 0.884216\n",
      "Train Epoch:   3 [ 15360/ 99878 (15%)]\tLoss: 0.721193\n",
      "Train Epoch:   3 [ 20480/ 99878 (20%)]\tLoss: 0.817366\n",
      "Train Epoch:   3 [ 25600/ 99878 (26%)]\tLoss: 0.806626\n",
      "Train Epoch:   3 [ 30720/ 99878 (31%)]\tLoss: 0.786963\n",
      "Train Epoch:   3 [ 35840/ 99878 (36%)]\tLoss: 0.808305\n",
      "Train Epoch:   3 [ 40960/ 99878 (41%)]\tLoss: 0.852199\n",
      "Train Epoch:   3 [ 46080/ 99878 (46%)]\tLoss: 0.828496\n",
      "Train Epoch:   3 [ 51200/ 99878 (51%)]\tLoss: 0.797670\n",
      "Train Epoch:   3 [ 56320/ 99878 (56%)]\tLoss: 0.810407\n",
      "Train Epoch:   3 [ 61440/ 99878 (61%)]\tLoss: 0.785227\n",
      "Train Epoch:   3 [ 66560/ 99878 (66%)]\tLoss: 0.763935\n",
      "Train Epoch:   3 [ 71680/ 99878 (71%)]\tLoss: 0.829262\n",
      "Train Epoch:   3 [ 76800/ 99878 (77%)]\tLoss: 0.813706\n",
      "Train Epoch:   3 [ 81920/ 99878 (82%)]\tLoss: 0.836620\n",
      "Train Epoch:   3 [ 87040/ 99878 (87%)]\tLoss: 0.792593\n",
      "Train Epoch:   3 [ 92160/ 99878 (92%)]\tLoss: 0.776865\n",
      "Train Epoch:   3 [ 97280/ 99878 (97%)]\tLoss: 0.824323\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0007, Accuracy: 72761/99878 (72.85%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   4 [     0/ 99878 (0%)]\tLoss: 0.764336\n",
      "Train Epoch:   4 [  5120/ 99878 (5%)]\tLoss: 0.691256\n",
      "Train Epoch:   4 [ 10240/ 99878 (10%)]\tLoss: 0.750161\n",
      "Train Epoch:   4 [ 15360/ 99878 (15%)]\tLoss: 0.703482\n",
      "Train Epoch:   4 [ 20480/ 99878 (20%)]\tLoss: 0.667761\n",
      "Train Epoch:   4 [ 25600/ 99878 (26%)]\tLoss: 0.695054\n",
      "Train Epoch:   4 [ 30720/ 99878 (31%)]\tLoss: 0.762090\n",
      "Train Epoch:   4 [ 35840/ 99878 (36%)]\tLoss: 0.713238\n",
      "Train Epoch:   4 [ 40960/ 99878 (41%)]\tLoss: 0.734977\n",
      "Train Epoch:   4 [ 46080/ 99878 (46%)]\tLoss: 0.757745\n",
      "Train Epoch:   4 [ 51200/ 99878 (51%)]\tLoss: 0.682969\n",
      "Train Epoch:   4 [ 56320/ 99878 (56%)]\tLoss: 0.724996\n",
      "Train Epoch:   4 [ 61440/ 99878 (61%)]\tLoss: 0.723467\n",
      "Train Epoch:   4 [ 66560/ 99878 (66%)]\tLoss: 0.754255\n",
      "Train Epoch:   4 [ 71680/ 99878 (71%)]\tLoss: 0.719479\n",
      "Train Epoch:   4 [ 76800/ 99878 (77%)]\tLoss: 0.717614\n",
      "Train Epoch:   4 [ 81920/ 99878 (82%)]\tLoss: 0.713665\n",
      "Train Epoch:   4 [ 87040/ 99878 (87%)]\tLoss: 0.763104\n",
      "Train Epoch:   4 [ 92160/ 99878 (92%)]\tLoss: 0.659926\n",
      "Train Epoch:   4 [ 97280/ 99878 (97%)]\tLoss: 0.749915\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0006, Accuracy: 75084/99878 (75.18%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   5 [     0/ 99878 (0%)]\tLoss: 0.627133\n",
      "Train Epoch:   5 [  5120/ 99878 (5%)]\tLoss: 0.640655\n",
      "Train Epoch:   5 [ 10240/ 99878 (10%)]\tLoss: 0.659440\n",
      "Train Epoch:   5 [ 15360/ 99878 (15%)]\tLoss: 0.670856\n",
      "Train Epoch:   5 [ 20480/ 99878 (20%)]\tLoss: 0.625624\n",
      "Train Epoch:   5 [ 25600/ 99878 (26%)]\tLoss: 0.665708\n",
      "Train Epoch:   5 [ 30720/ 99878 (31%)]\tLoss: 0.645836\n",
      "Train Epoch:   5 [ 35840/ 99878 (36%)]\tLoss: 0.672801\n",
      "Train Epoch:   5 [ 40960/ 99878 (41%)]\tLoss: 0.654762\n",
      "Train Epoch:   5 [ 46080/ 99878 (46%)]\tLoss: 0.672680\n",
      "Train Epoch:   5 [ 51200/ 99878 (51%)]\tLoss: 0.679380\n",
      "Train Epoch:   5 [ 56320/ 99878 (56%)]\tLoss: 0.712476\n",
      "Train Epoch:   5 [ 61440/ 99878 (61%)]\tLoss: 0.710661\n",
      "Train Epoch:   5 [ 66560/ 99878 (66%)]\tLoss: 0.660127\n",
      "Train Epoch:   5 [ 71680/ 99878 (71%)]\tLoss: 0.660413\n",
      "Train Epoch:   5 [ 76800/ 99878 (77%)]\tLoss: 0.675721\n",
      "Train Epoch:   5 [ 81920/ 99878 (82%)]\tLoss: 0.647118\n",
      "Train Epoch:   5 [ 87040/ 99878 (87%)]\tLoss: 0.656243\n",
      "Train Epoch:   5 [ 92160/ 99878 (92%)]\tLoss: 0.671742\n",
      "Train Epoch:   5 [ 97280/ 99878 (97%)]\tLoss: 0.682211\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0006, Accuracy: 77243/99878 (77.34%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   6 [     0/ 99878 (0%)]\tLoss: 0.631371\n",
      "Train Epoch:   6 [  5120/ 99878 (5%)]\tLoss: 0.596505\n",
      "Train Epoch:   6 [ 10240/ 99878 (10%)]\tLoss: 0.534698\n",
      "Train Epoch:   6 [ 15360/ 99878 (15%)]\tLoss: 0.605325\n",
      "Train Epoch:   6 [ 20480/ 99878 (20%)]\tLoss: 0.574825\n",
      "Train Epoch:   6 [ 25600/ 99878 (26%)]\tLoss: 0.585908\n",
      "Train Epoch:   6 [ 30720/ 99878 (31%)]\tLoss: 0.612322\n",
      "Train Epoch:   6 [ 35840/ 99878 (36%)]\tLoss: 0.571344\n",
      "Train Epoch:   6 [ 40960/ 99878 (41%)]\tLoss: 0.635900\n",
      "Train Epoch:   6 [ 46080/ 99878 (46%)]\tLoss: 0.621074\n",
      "Train Epoch:   6 [ 51200/ 99878 (51%)]\tLoss: 0.626415\n",
      "Train Epoch:   6 [ 56320/ 99878 (56%)]\tLoss: 0.594380\n",
      "Train Epoch:   6 [ 61440/ 99878 (61%)]\tLoss: 0.626672\n",
      "Train Epoch:   6 [ 66560/ 99878 (66%)]\tLoss: 0.643168\n",
      "Train Epoch:   6 [ 71680/ 99878 (71%)]\tLoss: 0.635455\n",
      "Train Epoch:   6 [ 76800/ 99878 (77%)]\tLoss: 0.645094\n",
      "Train Epoch:   6 [ 81920/ 99878 (82%)]\tLoss: 0.604760\n",
      "Train Epoch:   6 [ 87040/ 99878 (87%)]\tLoss: 0.602556\n",
      "Train Epoch:   6 [ 92160/ 99878 (92%)]\tLoss: 0.646192\n",
      "Train Epoch:   6 [ 97280/ 99878 (97%)]\tLoss: 0.664205\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0005, Accuracy: 79431/99878 (79.53%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   7 [     0/ 99878 (0%)]\tLoss: 0.600103\n",
      "Train Epoch:   7 [  5120/ 99878 (5%)]\tLoss: 0.517031\n",
      "Train Epoch:   7 [ 10240/ 99878 (10%)]\tLoss: 0.544654\n",
      "Train Epoch:   7 [ 15360/ 99878 (15%)]\tLoss: 0.553075\n",
      "Train Epoch:   7 [ 20480/ 99878 (20%)]\tLoss: 0.572093\n",
      "Train Epoch:   7 [ 25600/ 99878 (26%)]\tLoss: 0.528952\n",
      "Train Epoch:   7 [ 30720/ 99878 (31%)]\tLoss: 0.595056\n",
      "Train Epoch:   7 [ 35840/ 99878 (36%)]\tLoss: 0.523302\n",
      "Train Epoch:   7 [ 40960/ 99878 (41%)]\tLoss: 0.564095\n",
      "Train Epoch:   7 [ 46080/ 99878 (46%)]\tLoss: 0.581281\n",
      "Train Epoch:   7 [ 51200/ 99878 (51%)]\tLoss: 0.568297\n",
      "Train Epoch:   7 [ 56320/ 99878 (56%)]\tLoss: 0.612501\n",
      "Train Epoch:   7 [ 61440/ 99878 (61%)]\tLoss: 0.583954\n",
      "Train Epoch:   7 [ 66560/ 99878 (66%)]\tLoss: 0.627136\n",
      "Train Epoch:   7 [ 71680/ 99878 (71%)]\tLoss: 0.645382\n",
      "Train Epoch:   7 [ 76800/ 99878 (77%)]\tLoss: 0.590935\n",
      "Train Epoch:   7 [ 81920/ 99878 (82%)]\tLoss: 0.564851\n",
      "Train Epoch:   7 [ 87040/ 99878 (87%)]\tLoss: 0.592698\n",
      "Train Epoch:   7 [ 92160/ 99878 (92%)]\tLoss: 0.629175\n",
      "Train Epoch:   7 [ 97280/ 99878 (97%)]\tLoss: 0.613294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0005, Accuracy: 81152/99878 (81.25%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   8 [     0/ 99878 (0%)]\tLoss: 0.482180\n",
      "Train Epoch:   8 [  5120/ 99878 (5%)]\tLoss: 0.498631\n",
      "Train Epoch:   8 [ 10240/ 99878 (10%)]\tLoss: 0.450071\n",
      "Train Epoch:   8 [ 15360/ 99878 (15%)]\tLoss: 0.498003\n",
      "Train Epoch:   8 [ 20480/ 99878 (20%)]\tLoss: 0.493541\n",
      "Train Epoch:   8 [ 25600/ 99878 (26%)]\tLoss: 0.471754\n",
      "Train Epoch:   8 [ 30720/ 99878 (31%)]\tLoss: 0.488548\n",
      "Train Epoch:   8 [ 35840/ 99878 (36%)]\tLoss: 0.459567\n",
      "Train Epoch:   8 [ 40960/ 99878 (41%)]\tLoss: 0.478562\n",
      "Train Epoch:   8 [ 46080/ 99878 (46%)]\tLoss: 0.500271\n",
      "Train Epoch:   8 [ 51200/ 99878 (51%)]\tLoss: 0.468820\n",
      "Train Epoch:   8 [ 56320/ 99878 (56%)]\tLoss: 0.529353\n",
      "Train Epoch:   8 [ 61440/ 99878 (61%)]\tLoss: 0.485995\n",
      "Train Epoch:   8 [ 66560/ 99878 (66%)]\tLoss: 0.468920\n",
      "Train Epoch:   8 [ 71680/ 99878 (71%)]\tLoss: 0.440538\n",
      "Train Epoch:   8 [ 76800/ 99878 (77%)]\tLoss: 0.495202\n",
      "Train Epoch:   8 [ 81920/ 99878 (82%)]\tLoss: 0.535142\n",
      "Train Epoch:   8 [ 87040/ 99878 (87%)]\tLoss: 0.493197\n",
      "Train Epoch:   8 [ 92160/ 99878 (92%)]\tLoss: 0.468219\n",
      "Train Epoch:   8 [ 97280/ 99878 (97%)]\tLoss: 0.493180\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0004, Accuracy: 83400/99878 (83.50%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:   9 [     0/ 99878 (0%)]\tLoss: 0.456597\n",
      "Train Epoch:   9 [  5120/ 99878 (5%)]\tLoss: 0.466886\n",
      "Train Epoch:   9 [ 10240/ 99878 (10%)]\tLoss: 0.437101\n",
      "Train Epoch:   9 [ 15360/ 99878 (15%)]\tLoss: 0.448282\n",
      "Train Epoch:   9 [ 20480/ 99878 (20%)]\tLoss: 0.418950\n",
      "Train Epoch:   9 [ 25600/ 99878 (26%)]\tLoss: 0.450072\n",
      "Train Epoch:   9 [ 30720/ 99878 (31%)]\tLoss: 0.470000\n",
      "Train Epoch:   9 [ 35840/ 99878 (36%)]\tLoss: 0.453574\n",
      "Train Epoch:   9 [ 40960/ 99878 (41%)]\tLoss: 0.421687\n",
      "Train Epoch:   9 [ 46080/ 99878 (46%)]\tLoss: 0.436432\n",
      "Train Epoch:   9 [ 51200/ 99878 (51%)]\tLoss: 0.486055\n",
      "Train Epoch:   9 [ 56320/ 99878 (56%)]\tLoss: 0.459324\n",
      "Train Epoch:   9 [ 61440/ 99878 (61%)]\tLoss: 0.485180\n",
      "Train Epoch:   9 [ 66560/ 99878 (66%)]\tLoss: 0.447941\n",
      "Train Epoch:   9 [ 71680/ 99878 (71%)]\tLoss: 0.449384\n",
      "Train Epoch:   9 [ 76800/ 99878 (77%)]\tLoss: 0.468610\n",
      "Train Epoch:   9 [ 81920/ 99878 (82%)]\tLoss: 0.427766\n",
      "Train Epoch:   9 [ 87040/ 99878 (87%)]\tLoss: 0.433722\n",
      "Train Epoch:   9 [ 92160/ 99878 (92%)]\tLoss: 0.459202\n",
      "Train Epoch:   9 [ 97280/ 99878 (97%)]\tLoss: 0.486173\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0004, Accuracy: 84785/99878 (84.89%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  10 [     0/ 99878 (0%)]\tLoss: 0.394663\n",
      "Train Epoch:  10 [  5120/ 99878 (5%)]\tLoss: 0.440890\n",
      "Train Epoch:  10 [ 10240/ 99878 (10%)]\tLoss: 0.443820\n",
      "Train Epoch:  10 [ 15360/ 99878 (15%)]\tLoss: 0.419166\n",
      "Train Epoch:  10 [ 20480/ 99878 (20%)]\tLoss: 0.390555\n",
      "Train Epoch:  10 [ 25600/ 99878 (26%)]\tLoss: 0.412775\n",
      "Train Epoch:  10 [ 30720/ 99878 (31%)]\tLoss: 0.428634\n",
      "Train Epoch:  10 [ 35840/ 99878 (36%)]\tLoss: 0.437402\n",
      "Train Epoch:  10 [ 40960/ 99878 (41%)]\tLoss: 0.414724\n",
      "Train Epoch:  10 [ 46080/ 99878 (46%)]\tLoss: 0.488179\n",
      "Train Epoch:  10 [ 51200/ 99878 (51%)]\tLoss: 0.478583\n",
      "Train Epoch:  10 [ 56320/ 99878 (56%)]\tLoss: 0.448006\n",
      "Train Epoch:  10 [ 61440/ 99878 (61%)]\tLoss: 0.414219\n",
      "Train Epoch:  10 [ 66560/ 99878 (66%)]\tLoss: 0.408111\n",
      "Train Epoch:  10 [ 71680/ 99878 (71%)]\tLoss: 0.447752\n",
      "Train Epoch:  10 [ 76800/ 99878 (77%)]\tLoss: 0.411677\n",
      "Train Epoch:  10 [ 81920/ 99878 (82%)]\tLoss: 0.449979\n",
      "Train Epoch:  10 [ 87040/ 99878 (87%)]\tLoss: 0.432497\n",
      "Train Epoch:  10 [ 92160/ 99878 (92%)]\tLoss: 0.431813\n",
      "Train Epoch:  10 [ 97280/ 99878 (97%)]\tLoss: 0.456315\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0004, Accuracy: 85819/99878 (85.92%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  11 [     0/ 99878 (0%)]\tLoss: 0.363861\n",
      "Train Epoch:  11 [  5120/ 99878 (5%)]\tLoss: 0.394341\n",
      "Train Epoch:  11 [ 10240/ 99878 (10%)]\tLoss: 0.420097\n",
      "Train Epoch:  11 [ 15360/ 99878 (15%)]\tLoss: 0.427708\n",
      "Train Epoch:  11 [ 20480/ 99878 (20%)]\tLoss: 0.400070\n",
      "Train Epoch:  11 [ 25600/ 99878 (26%)]\tLoss: 0.386610\n",
      "Train Epoch:  11 [ 30720/ 99878 (31%)]\tLoss: 0.391257\n",
      "Train Epoch:  11 [ 35840/ 99878 (36%)]\tLoss: 0.414562\n",
      "Train Epoch:  11 [ 40960/ 99878 (41%)]\tLoss: 0.407698\n",
      "Train Epoch:  11 [ 46080/ 99878 (46%)]\tLoss: 0.367330\n",
      "Train Epoch:  11 [ 51200/ 99878 (51%)]\tLoss: 0.383982\n",
      "Train Epoch:  11 [ 56320/ 99878 (56%)]\tLoss: 0.366545\n",
      "Train Epoch:  11 [ 61440/ 99878 (61%)]\tLoss: 0.424532\n",
      "Train Epoch:  11 [ 66560/ 99878 (66%)]\tLoss: 0.394572\n",
      "Train Epoch:  11 [ 71680/ 99878 (71%)]\tLoss: 0.429982\n",
      "Train Epoch:  11 [ 76800/ 99878 (77%)]\tLoss: 0.357913\n",
      "Train Epoch:  11 [ 81920/ 99878 (82%)]\tLoss: 0.443179\n",
      "Train Epoch:  11 [ 87040/ 99878 (87%)]\tLoss: 0.399181\n",
      "Train Epoch:  11 [ 92160/ 99878 (92%)]\tLoss: 0.448209\n",
      "Train Epoch:  11 [ 97280/ 99878 (97%)]\tLoss: 0.376252\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0004, Accuracy: 86697/99878 (86.80%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  12 [     0/ 99878 (0%)]\tLoss: 0.371003\n",
      "Train Epoch:  12 [  5120/ 99878 (5%)]\tLoss: 0.365064\n",
      "Train Epoch:  12 [ 10240/ 99878 (10%)]\tLoss: 0.341743\n",
      "Train Epoch:  12 [ 15360/ 99878 (15%)]\tLoss: 0.406373\n",
      "Train Epoch:  12 [ 20480/ 99878 (20%)]\tLoss: 0.399257\n",
      "Train Epoch:  12 [ 25600/ 99878 (26%)]\tLoss: 0.403479\n",
      "Train Epoch:  12 [ 30720/ 99878 (31%)]\tLoss: 0.412729\n",
      "Train Epoch:  12 [ 35840/ 99878 (36%)]\tLoss: 0.418727\n",
      "Train Epoch:  12 [ 40960/ 99878 (41%)]\tLoss: 0.386263\n",
      "Train Epoch:  12 [ 46080/ 99878 (46%)]\tLoss: 0.393939\n",
      "Train Epoch:  12 [ 51200/ 99878 (51%)]\tLoss: 0.380756\n",
      "Train Epoch:  12 [ 56320/ 99878 (56%)]\tLoss: 0.376091\n",
      "Train Epoch:  12 [ 61440/ 99878 (61%)]\tLoss: 0.392078\n",
      "Train Epoch:  12 [ 66560/ 99878 (66%)]\tLoss: 0.392513\n",
      "Train Epoch:  12 [ 71680/ 99878 (71%)]\tLoss: 0.360915\n",
      "Train Epoch:  12 [ 76800/ 99878 (77%)]\tLoss: 0.393486\n",
      "Train Epoch:  12 [ 81920/ 99878 (82%)]\tLoss: 0.392499\n",
      "Train Epoch:  12 [ 87040/ 99878 (87%)]\tLoss: 0.414736\n",
      "Train Epoch:  12 [ 92160/ 99878 (92%)]\tLoss: 0.387641\n",
      "Train Epoch:  12 [ 97280/ 99878 (97%)]\tLoss: 0.414963\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0004, Accuracy: 87450/99878 (87.56%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  13 [     0/ 99878 (0%)]\tLoss: 0.319570\n",
      "Train Epoch:  13 [  5120/ 99878 (5%)]\tLoss: 0.400073\n",
      "Train Epoch:  13 [ 10240/ 99878 (10%)]\tLoss: 0.374663\n",
      "Train Epoch:  13 [ 15360/ 99878 (15%)]\tLoss: 0.399918\n",
      "Train Epoch:  13 [ 20480/ 99878 (20%)]\tLoss: 0.382979\n",
      "Train Epoch:  13 [ 25600/ 99878 (26%)]\tLoss: 0.387581\n",
      "Train Epoch:  13 [ 30720/ 99878 (31%)]\tLoss: 0.364780\n",
      "Train Epoch:  13 [ 35840/ 99878 (36%)]\tLoss: 0.355813\n",
      "Train Epoch:  13 [ 40960/ 99878 (41%)]\tLoss: 0.383530\n",
      "Train Epoch:  13 [ 46080/ 99878 (46%)]\tLoss: 0.374795\n",
      "Train Epoch:  13 [ 51200/ 99878 (51%)]\tLoss: 0.372545\n",
      "Train Epoch:  13 [ 56320/ 99878 (56%)]\tLoss: 0.384275\n",
      "Train Epoch:  13 [ 61440/ 99878 (61%)]\tLoss: 0.337421\n",
      "Train Epoch:  13 [ 66560/ 99878 (66%)]\tLoss: 0.357001\n",
      "Train Epoch:  13 [ 71680/ 99878 (71%)]\tLoss: 0.355715\n",
      "Train Epoch:  13 [ 76800/ 99878 (77%)]\tLoss: 0.389763\n",
      "Train Epoch:  13 [ 81920/ 99878 (82%)]\tLoss: 0.367043\n",
      "Train Epoch:  13 [ 87040/ 99878 (87%)]\tLoss: 0.366156\n",
      "Train Epoch:  13 [ 92160/ 99878 (92%)]\tLoss: 0.398851\n",
      "Train Epoch:  13 [ 97280/ 99878 (97%)]\tLoss: 0.369004\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0003, Accuracy: 88204/99878 (88.31%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  14 [     0/ 99878 (0%)]\tLoss: 0.375736\n",
      "Train Epoch:  14 [  5120/ 99878 (5%)]\tLoss: 0.356904\n",
      "Train Epoch:  14 [ 10240/ 99878 (10%)]\tLoss: 0.354627\n",
      "Train Epoch:  14 [ 15360/ 99878 (15%)]\tLoss: 0.320077\n",
      "Train Epoch:  14 [ 20480/ 99878 (20%)]\tLoss: 0.379211\n",
      "Train Epoch:  14 [ 25600/ 99878 (26%)]\tLoss: 0.310190\n",
      "Train Epoch:  14 [ 30720/ 99878 (31%)]\tLoss: 0.376911\n",
      "Train Epoch:  14 [ 35840/ 99878 (36%)]\tLoss: 0.356039\n",
      "Train Epoch:  14 [ 40960/ 99878 (41%)]\tLoss: 0.356826\n",
      "Train Epoch:  14 [ 46080/ 99878 (46%)]\tLoss: 0.370601\n",
      "Train Epoch:  14 [ 51200/ 99878 (51%)]\tLoss: 0.363807\n",
      "Train Epoch:  14 [ 56320/ 99878 (56%)]\tLoss: 0.338983\n",
      "Train Epoch:  14 [ 61440/ 99878 (61%)]\tLoss: 0.372079\n",
      "Train Epoch:  14 [ 66560/ 99878 (66%)]\tLoss: 0.385112\n",
      "Train Epoch:  14 [ 71680/ 99878 (71%)]\tLoss: 0.303117\n",
      "Train Epoch:  14 [ 76800/ 99878 (77%)]\tLoss: 0.319390\n",
      "Train Epoch:  14 [ 81920/ 99878 (82%)]\tLoss: 0.397813\n",
      "Train Epoch:  14 [ 87040/ 99878 (87%)]\tLoss: 0.422523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:  14 [ 92160/ 99878 (92%)]\tLoss: 0.367608\n",
      "Train Epoch:  14 [ 97280/ 99878 (97%)]\tLoss: 0.346335\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0003, Accuracy: 88914/99878 (89.02%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  15 [     0/ 99878 (0%)]\tLoss: 0.354435\n",
      "Train Epoch:  15 [  5120/ 99878 (5%)]\tLoss: 0.348075\n",
      "Train Epoch:  15 [ 10240/ 99878 (10%)]\tLoss: 0.360436\n",
      "Train Epoch:  15 [ 15360/ 99878 (15%)]\tLoss: 0.324017\n",
      "Train Epoch:  15 [ 20480/ 99878 (20%)]\tLoss: 0.398845\n",
      "Train Epoch:  15 [ 25600/ 99878 (26%)]\tLoss: 0.338175\n",
      "Train Epoch:  15 [ 30720/ 99878 (31%)]\tLoss: 0.355997\n",
      "Train Epoch:  15 [ 35840/ 99878 (36%)]\tLoss: 0.383796\n",
      "Train Epoch:  15 [ 40960/ 99878 (41%)]\tLoss: 0.336803\n",
      "Train Epoch:  15 [ 46080/ 99878 (46%)]\tLoss: 0.328314\n",
      "Train Epoch:  15 [ 51200/ 99878 (51%)]\tLoss: 0.285292\n",
      "Train Epoch:  15 [ 56320/ 99878 (56%)]\tLoss: 0.335222\n",
      "Train Epoch:  15 [ 61440/ 99878 (61%)]\tLoss: 0.318802\n",
      "Train Epoch:  15 [ 66560/ 99878 (66%)]\tLoss: 0.357217\n",
      "Train Epoch:  15 [ 71680/ 99878 (71%)]\tLoss: 0.341119\n",
      "Train Epoch:  15 [ 76800/ 99878 (77%)]\tLoss: 0.326558\n",
      "Train Epoch:  15 [ 81920/ 99878 (82%)]\tLoss: 0.353882\n",
      "Train Epoch:  15 [ 87040/ 99878 (87%)]\tLoss: 0.327389\n",
      "Train Epoch:  15 [ 92160/ 99878 (92%)]\tLoss: 0.355870\n",
      "Train Epoch:  15 [ 97280/ 99878 (97%)]\tLoss: 0.311294\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0003, Accuracy: 89171/99878 (89.28%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  16 [     0/ 99878 (0%)]\tLoss: 0.299943\n",
      "Train Epoch:  16 [  5120/ 99878 (5%)]\tLoss: 0.304149\n",
      "Train Epoch:  16 [ 10240/ 99878 (10%)]\tLoss: 0.324291\n",
      "Train Epoch:  16 [ 15360/ 99878 (15%)]\tLoss: 0.306335\n",
      "Train Epoch:  16 [ 20480/ 99878 (20%)]\tLoss: 0.305002\n",
      "Train Epoch:  16 [ 25600/ 99878 (26%)]\tLoss: 0.343818\n",
      "Train Epoch:  16 [ 30720/ 99878 (31%)]\tLoss: 0.314166\n",
      "Train Epoch:  16 [ 35840/ 99878 (36%)]\tLoss: 0.361177\n",
      "Train Epoch:  16 [ 40960/ 99878 (41%)]\tLoss: 0.335224\n",
      "Train Epoch:  16 [ 46080/ 99878 (46%)]\tLoss: 0.333287\n",
      "Train Epoch:  16 [ 51200/ 99878 (51%)]\tLoss: 0.329076\n",
      "Train Epoch:  16 [ 56320/ 99878 (56%)]\tLoss: 0.305697\n",
      "Train Epoch:  16 [ 61440/ 99878 (61%)]\tLoss: 0.306645\n",
      "Train Epoch:  16 [ 66560/ 99878 (66%)]\tLoss: 0.320328\n",
      "Train Epoch:  16 [ 71680/ 99878 (71%)]\tLoss: 0.310589\n",
      "Train Epoch:  16 [ 76800/ 99878 (77%)]\tLoss: 0.314357\n",
      "Train Epoch:  16 [ 81920/ 99878 (82%)]\tLoss: 0.320791\n",
      "Train Epoch:  16 [ 87040/ 99878 (87%)]\tLoss: 0.304231\n",
      "Train Epoch:  16 [ 92160/ 99878 (92%)]\tLoss: 0.323078\n",
      "Train Epoch:  16 [ 97280/ 99878 (97%)]\tLoss: 0.339028\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0003, Accuracy: 89318/99878 (89.43%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  17 [     0/ 99878 (0%)]\tLoss: 0.328162\n",
      "Train Epoch:  17 [  5120/ 99878 (5%)]\tLoss: 0.309884\n",
      "Train Epoch:  17 [ 10240/ 99878 (10%)]\tLoss: 0.343795\n",
      "Train Epoch:  17 [ 15360/ 99878 (15%)]\tLoss: 0.316897\n",
      "Train Epoch:  17 [ 20480/ 99878 (20%)]\tLoss: 0.352488\n",
      "Train Epoch:  17 [ 25600/ 99878 (26%)]\tLoss: 0.345861\n",
      "Train Epoch:  17 [ 30720/ 99878 (31%)]\tLoss: 0.300376\n",
      "Train Epoch:  17 [ 35840/ 99878 (36%)]\tLoss: 0.285663\n",
      "Train Epoch:  17 [ 40960/ 99878 (41%)]\tLoss: 0.316304\n",
      "Train Epoch:  17 [ 46080/ 99878 (46%)]\tLoss: 0.358467\n",
      "Train Epoch:  17 [ 51200/ 99878 (51%)]\tLoss: 0.319573\n",
      "Train Epoch:  17 [ 56320/ 99878 (56%)]\tLoss: 0.311306\n",
      "Train Epoch:  17 [ 61440/ 99878 (61%)]\tLoss: 0.284278\n",
      "Train Epoch:  17 [ 66560/ 99878 (66%)]\tLoss: 0.281433\n",
      "Train Epoch:  17 [ 71680/ 99878 (71%)]\tLoss: 0.319243\n",
      "Train Epoch:  17 [ 76800/ 99878 (77%)]\tLoss: 0.357225\n",
      "Train Epoch:  17 [ 81920/ 99878 (82%)]\tLoss: 0.319573\n",
      "Train Epoch:  17 [ 87040/ 99878 (87%)]\tLoss: 0.306123\n",
      "Train Epoch:  17 [ 92160/ 99878 (92%)]\tLoss: 0.308057\n",
      "Train Epoch:  17 [ 97280/ 99878 (97%)]\tLoss: 0.321633\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0003, Accuracy: 89443/99878 (89.55%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  18 [     0/ 99878 (0%)]\tLoss: 0.321239\n",
      "Train Epoch:  18 [  5120/ 99878 (5%)]\tLoss: 0.313716\n",
      "Train Epoch:  18 [ 10240/ 99878 (10%)]\tLoss: 0.338492\n",
      "Train Epoch:  18 [ 15360/ 99878 (15%)]\tLoss: 0.331008\n",
      "Train Epoch:  18 [ 20480/ 99878 (20%)]\tLoss: 0.319727\n",
      "Train Epoch:  18 [ 25600/ 99878 (26%)]\tLoss: 0.318524\n",
      "Train Epoch:  18 [ 30720/ 99878 (31%)]\tLoss: 0.336073\n",
      "Train Epoch:  18 [ 35840/ 99878 (36%)]\tLoss: 0.319630\n",
      "Train Epoch:  18 [ 40960/ 99878 (41%)]\tLoss: 0.344743\n",
      "Train Epoch:  18 [ 46080/ 99878 (46%)]\tLoss: 0.306879\n",
      "Train Epoch:  18 [ 51200/ 99878 (51%)]\tLoss: 0.325830\n",
      "Train Epoch:  18 [ 56320/ 99878 (56%)]\tLoss: 0.325678\n",
      "Train Epoch:  18 [ 61440/ 99878 (61%)]\tLoss: 0.315750\n",
      "Train Epoch:  18 [ 66560/ 99878 (66%)]\tLoss: 0.305533\n",
      "Train Epoch:  18 [ 71680/ 99878 (71%)]\tLoss: 0.324564\n",
      "Train Epoch:  18 [ 76800/ 99878 (77%)]\tLoss: 0.331043\n",
      "Train Epoch:  18 [ 81920/ 99878 (82%)]\tLoss: 0.312904\n",
      "Train Epoch:  18 [ 87040/ 99878 (87%)]\tLoss: 0.306955\n",
      "Train Epoch:  18 [ 92160/ 99878 (92%)]\tLoss: 0.298784\n",
      "Train Epoch:  18 [ 97280/ 99878 (97%)]\tLoss: 0.313433\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0003, Accuracy: 89580/99878 (89.69%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  19 [     0/ 99878 (0%)]\tLoss: 0.333500\n",
      "Train Epoch:  19 [  5120/ 99878 (5%)]\tLoss: 0.281885\n",
      "Train Epoch:  19 [ 10240/ 99878 (10%)]\tLoss: 0.360871\n",
      "Train Epoch:  19 [ 15360/ 99878 (15%)]\tLoss: 0.326669\n",
      "Train Epoch:  19 [ 20480/ 99878 (20%)]\tLoss: 0.280177\n",
      "Train Epoch:  19 [ 25600/ 99878 (26%)]\tLoss: 0.355315\n",
      "Train Epoch:  19 [ 30720/ 99878 (31%)]\tLoss: 0.334455\n",
      "Train Epoch:  19 [ 35840/ 99878 (36%)]\tLoss: 0.316736\n",
      "Train Epoch:  19 [ 40960/ 99878 (41%)]\tLoss: 0.290673\n",
      "Train Epoch:  19 [ 46080/ 99878 (46%)]\tLoss: 0.320201\n",
      "Train Epoch:  19 [ 51200/ 99878 (51%)]\tLoss: 0.290213\n",
      "Train Epoch:  19 [ 56320/ 99878 (56%)]\tLoss: 0.281667\n",
      "Train Epoch:  19 [ 61440/ 99878 (61%)]\tLoss: 0.302277\n",
      "Train Epoch:  19 [ 66560/ 99878 (66%)]\tLoss: 0.333242\n",
      "Train Epoch:  19 [ 71680/ 99878 (71%)]\tLoss: 0.335544\n",
      "Train Epoch:  19 [ 76800/ 99878 (77%)]\tLoss: 0.326771\n",
      "Train Epoch:  19 [ 81920/ 99878 (82%)]\tLoss: 0.324330\n",
      "Train Epoch:  19 [ 87040/ 99878 (87%)]\tLoss: 0.291865\n",
      "Train Epoch:  19 [ 92160/ 99878 (92%)]\tLoss: 0.318965\n",
      "Train Epoch:  19 [ 97280/ 99878 (97%)]\tLoss: 0.319422\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0003, Accuracy: 89688/99878 (89.80%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  20 [     0/ 99878 (0%)]\tLoss: 0.294714\n",
      "Train Epoch:  20 [  5120/ 99878 (5%)]\tLoss: 0.322732\n",
      "Train Epoch:  20 [ 10240/ 99878 (10%)]\tLoss: 0.291147\n",
      "Train Epoch:  20 [ 15360/ 99878 (15%)]\tLoss: 0.306312\n",
      "Train Epoch:  20 [ 20480/ 99878 (20%)]\tLoss: 0.299903\n",
      "Train Epoch:  20 [ 25600/ 99878 (26%)]\tLoss: 0.328751\n",
      "Train Epoch:  20 [ 30720/ 99878 (31%)]\tLoss: 0.294632\n",
      "Train Epoch:  20 [ 35840/ 99878 (36%)]\tLoss: 0.269111\n",
      "Train Epoch:  20 [ 40960/ 99878 (41%)]\tLoss: 0.319827\n",
      "Train Epoch:  20 [ 46080/ 99878 (46%)]\tLoss: 0.326454\n",
      "Train Epoch:  20 [ 51200/ 99878 (51%)]\tLoss: 0.314251\n",
      "Train Epoch:  20 [ 56320/ 99878 (56%)]\tLoss: 0.316627\n",
      "Train Epoch:  20 [ 61440/ 99878 (61%)]\tLoss: 0.280392\n",
      "Train Epoch:  20 [ 66560/ 99878 (66%)]\tLoss: 0.305249\n",
      "Train Epoch:  20 [ 71680/ 99878 (71%)]\tLoss: 0.344762\n",
      "Train Epoch:  20 [ 76800/ 99878 (77%)]\tLoss: 0.312723\n",
      "Train Epoch:  20 [ 81920/ 99878 (82%)]\tLoss: 0.331090\n",
      "Train Epoch:  20 [ 87040/ 99878 (87%)]\tLoss: 0.306755\n",
      "Train Epoch:  20 [ 92160/ 99878 (92%)]\tLoss: 0.345410\n",
      "Train Epoch:  20 [ 97280/ 99878 (97%)]\tLoss: 0.282084\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0003, Accuracy: 89798/99878 (89.91%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  21 [     0/ 99878 (0%)]\tLoss: 0.304845\n",
      "Train Epoch:  21 [  5120/ 99878 (5%)]\tLoss: 0.290205\n",
      "Train Epoch:  21 [ 10240/ 99878 (10%)]\tLoss: 0.233457\n",
      "Train Epoch:  21 [ 15360/ 99878 (15%)]\tLoss: 0.287651\n",
      "Train Epoch:  21 [ 20480/ 99878 (20%)]\tLoss: 0.308072\n",
      "Train Epoch:  21 [ 25600/ 99878 (26%)]\tLoss: 0.284620\n",
      "Train Epoch:  21 [ 30720/ 99878 (31%)]\tLoss: 0.284955\n",
      "Train Epoch:  21 [ 35840/ 99878 (36%)]\tLoss: 0.329678\n",
      "Train Epoch:  21 [ 40960/ 99878 (41%)]\tLoss: 0.313725\n",
      "Train Epoch:  21 [ 46080/ 99878 (46%)]\tLoss: 0.300332\n",
      "Train Epoch:  21 [ 51200/ 99878 (51%)]\tLoss: 0.331898\n",
      "Train Epoch:  21 [ 56320/ 99878 (56%)]\tLoss: 0.304046\n",
      "Train Epoch:  21 [ 61440/ 99878 (61%)]\tLoss: 0.277916\n",
      "Train Epoch:  21 [ 66560/ 99878 (66%)]\tLoss: 0.310448\n",
      "Train Epoch:  21 [ 71680/ 99878 (71%)]\tLoss: 0.333456\n",
      "Train Epoch:  21 [ 76800/ 99878 (77%)]\tLoss: 0.323042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:  21 [ 81920/ 99878 (82%)]\tLoss: 0.370353\n",
      "Train Epoch:  21 [ 87040/ 99878 (87%)]\tLoss: 0.302954\n",
      "Train Epoch:  21 [ 92160/ 99878 (92%)]\tLoss: 0.309683\n",
      "Train Epoch:  21 [ 97280/ 99878 (97%)]\tLoss: 0.311216\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0003, Accuracy: 89892/99878 (90.00%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  22 [     0/ 99878 (0%)]\tLoss: 0.281885\n",
      "Train Epoch:  22 [  5120/ 99878 (5%)]\tLoss: 0.317776\n",
      "Train Epoch:  22 [ 10240/ 99878 (10%)]\tLoss: 0.285335\n",
      "Train Epoch:  22 [ 15360/ 99878 (15%)]\tLoss: 0.315407\n",
      "Train Epoch:  22 [ 20480/ 99878 (20%)]\tLoss: 0.286114\n",
      "Train Epoch:  22 [ 25600/ 99878 (26%)]\tLoss: 0.337068\n",
      "Train Epoch:  22 [ 30720/ 99878 (31%)]\tLoss: 0.327817\n",
      "Train Epoch:  22 [ 35840/ 99878 (36%)]\tLoss: 0.281082\n",
      "Train Epoch:  22 [ 40960/ 99878 (41%)]\tLoss: 0.266568\n",
      "Train Epoch:  22 [ 46080/ 99878 (46%)]\tLoss: 0.317279\n",
      "Train Epoch:  22 [ 51200/ 99878 (51%)]\tLoss: 0.330515\n",
      "Train Epoch:  22 [ 56320/ 99878 (56%)]\tLoss: 0.304105\n",
      "Train Epoch:  22 [ 61440/ 99878 (61%)]\tLoss: 0.291979\n",
      "Train Epoch:  22 [ 66560/ 99878 (66%)]\tLoss: 0.286007\n",
      "Train Epoch:  22 [ 71680/ 99878 (71%)]\tLoss: 0.299355\n",
      "Train Epoch:  22 [ 76800/ 99878 (77%)]\tLoss: 0.319247\n",
      "Train Epoch:  22 [ 81920/ 99878 (82%)]\tLoss: 0.284701\n",
      "Train Epoch:  22 [ 87040/ 99878 (87%)]\tLoss: 0.273921\n",
      "Train Epoch:  22 [ 92160/ 99878 (92%)]\tLoss: 0.329254\n",
      "Train Epoch:  22 [ 97280/ 99878 (97%)]\tLoss: 0.316795\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0003, Accuracy: 89903/99878 (90.01%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  23 [     0/ 99878 (0%)]\tLoss: 0.302876\n",
      "Train Epoch:  23 [  5120/ 99878 (5%)]\tLoss: 0.318144\n",
      "Train Epoch:  23 [ 10240/ 99878 (10%)]\tLoss: 0.278988\n",
      "Train Epoch:  23 [ 15360/ 99878 (15%)]\tLoss: 0.307698\n",
      "Train Epoch:  23 [ 20480/ 99878 (20%)]\tLoss: 0.286503\n",
      "Train Epoch:  23 [ 25600/ 99878 (26%)]\tLoss: 0.298801\n",
      "Train Epoch:  23 [ 30720/ 99878 (31%)]\tLoss: 0.311088\n",
      "Train Epoch:  23 [ 35840/ 99878 (36%)]\tLoss: 0.309996\n",
      "Train Epoch:  23 [ 40960/ 99878 (41%)]\tLoss: 0.304565\n",
      "Train Epoch:  23 [ 46080/ 99878 (46%)]\tLoss: 0.309660\n",
      "Train Epoch:  23 [ 51200/ 99878 (51%)]\tLoss: 0.308925\n",
      "Train Epoch:  23 [ 56320/ 99878 (56%)]\tLoss: 0.318094\n",
      "Train Epoch:  23 [ 61440/ 99878 (61%)]\tLoss: 0.283120\n",
      "Train Epoch:  23 [ 66560/ 99878 (66%)]\tLoss: 0.293611\n",
      "Train Epoch:  23 [ 71680/ 99878 (71%)]\tLoss: 0.340679\n",
      "Train Epoch:  23 [ 76800/ 99878 (77%)]\tLoss: 0.326653\n",
      "Train Epoch:  23 [ 81920/ 99878 (82%)]\tLoss: 0.314407\n",
      "Train Epoch:  23 [ 87040/ 99878 (87%)]\tLoss: 0.283388\n",
      "Train Epoch:  23 [ 92160/ 99878 (92%)]\tLoss: 0.293683\n",
      "Train Epoch:  23 [ 97280/ 99878 (97%)]\tLoss: 0.336792\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0003, Accuracy: 89914/99878 (90.02%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  24 [     0/ 99878 (0%)]\tLoss: 0.285661\n",
      "Train Epoch:  24 [  5120/ 99878 (5%)]\tLoss: 0.304895\n",
      "Train Epoch:  24 [ 10240/ 99878 (10%)]\tLoss: 0.307518\n",
      "Train Epoch:  24 [ 15360/ 99878 (15%)]\tLoss: 0.306526\n",
      "Train Epoch:  24 [ 20480/ 99878 (20%)]\tLoss: 0.306976\n",
      "Train Epoch:  24 [ 25600/ 99878 (26%)]\tLoss: 0.306178\n",
      "Train Epoch:  24 [ 30720/ 99878 (31%)]\tLoss: 0.349759\n",
      "Train Epoch:  24 [ 35840/ 99878 (36%)]\tLoss: 0.319615\n",
      "Train Epoch:  24 [ 40960/ 99878 (41%)]\tLoss: 0.327669\n",
      "Train Epoch:  24 [ 46080/ 99878 (46%)]\tLoss: 0.315556\n",
      "Train Epoch:  24 [ 51200/ 99878 (51%)]\tLoss: 0.312071\n",
      "Train Epoch:  24 [ 56320/ 99878 (56%)]\tLoss: 0.311199\n",
      "Train Epoch:  24 [ 61440/ 99878 (61%)]\tLoss: 0.249376\n",
      "Train Epoch:  24 [ 66560/ 99878 (66%)]\tLoss: 0.287525\n",
      "Train Epoch:  24 [ 71680/ 99878 (71%)]\tLoss: 0.302516\n",
      "Train Epoch:  24 [ 76800/ 99878 (77%)]\tLoss: 0.288544\n",
      "Train Epoch:  24 [ 81920/ 99878 (82%)]\tLoss: 0.305009\n",
      "Train Epoch:  24 [ 87040/ 99878 (87%)]\tLoss: 0.344563\n",
      "Train Epoch:  24 [ 92160/ 99878 (92%)]\tLoss: 0.319983\n",
      "Train Epoch:  24 [ 97280/ 99878 (97%)]\tLoss: 0.301370\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0003, Accuracy: 89917/99878 (90.03%)\n",
      "\n",
      "\n",
      "* * * Training * * *\n",
      "Train Epoch:  25 [     0/ 99878 (0%)]\tLoss: 0.332155\n",
      "Train Epoch:  25 [  5120/ 99878 (5%)]\tLoss: 0.233370\n",
      "Train Epoch:  25 [ 10240/ 99878 (10%)]\tLoss: 0.325014\n",
      "Train Epoch:  25 [ 15360/ 99878 (15%)]\tLoss: 0.271040\n",
      "Train Epoch:  25 [ 20480/ 99878 (20%)]\tLoss: 0.275963\n",
      "Train Epoch:  25 [ 25600/ 99878 (26%)]\tLoss: 0.287904\n",
      "Train Epoch:  25 [ 30720/ 99878 (31%)]\tLoss: 0.329939\n",
      "Train Epoch:  25 [ 35840/ 99878 (36%)]\tLoss: 0.298579\n",
      "Train Epoch:  25 [ 40960/ 99878 (41%)]\tLoss: 0.318292\n",
      "Train Epoch:  25 [ 46080/ 99878 (46%)]\tLoss: 0.278243\n",
      "Train Epoch:  25 [ 51200/ 99878 (51%)]\tLoss: 0.305256\n",
      "Train Epoch:  25 [ 56320/ 99878 (56%)]\tLoss: 0.292098\n",
      "Train Epoch:  25 [ 61440/ 99878 (61%)]\tLoss: 0.316217\n",
      "Train Epoch:  25 [ 66560/ 99878 (66%)]\tLoss: 0.274434\n",
      "Train Epoch:  25 [ 71680/ 99878 (71%)]\tLoss: 0.297190\n",
      "Train Epoch:  25 [ 76800/ 99878 (77%)]\tLoss: 0.313500\n",
      "Train Epoch:  25 [ 81920/ 99878 (82%)]\tLoss: 0.312550\n",
      "Train Epoch:  25 [ 87040/ 99878 (87%)]\tLoss: 0.284244\n",
      "Train Epoch:  25 [ 92160/ 99878 (92%)]\tLoss: 0.294111\n",
      "Train Epoch:  25 [ 97280/ 99878 (97%)]\tLoss: 0.291693\n",
      "\n",
      "* * * Evaluating * * *\n",
      "Test set: Average loss: 0.0003, Accuracy: 89933/99878 (90.04%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = train(\n",
    "    model=model, train_loader=train_loader, test_loader=valid_loader,\n",
    "    device=device, optimizer=optimizer, lr_scheduler=lr_scheduler,\n",
    "    nb_epochs=nb_epochs, log_interval=log_interval\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados do treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max val acc: 90.04%\n"
     ]
    }
   ],
   "source": [
    "print('Max val acc: {:.2f}%'.format(max(history['val_acc'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
